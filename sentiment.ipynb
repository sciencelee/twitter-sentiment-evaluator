{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "absolute-cancer",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-perception",
   "metadata": {},
   "source": [
    "#### MY NOTES and research\n",
    "\n",
    "I started this project by doing all of the Deep NLP lessons at Flatiron in the appendix of Module 4\n",
    "This included:\n",
    "- Word embeddings\n",
    "- Word2vec\n",
    "- Sequence Models\n",
    "- Recurrant Neural Networks (RNN)\n",
    "- LSTM (Long Short term Membory) and GRU (Gated Recurrant Unit)\n",
    "\n",
    "I also did some code along and lab with word classifiers.\n",
    "RNN are good for time and sequenced classifications.  They can have vanishing and exploding gradient problems.  The modern equivalent to RNN is LSTM and GRU.  LSTM and GRU 'remember' and 'forget' data by feedback to the model throughout the sequence.  Gates keep only the most important info.  Neither is better, so you should try out both of them for these types of problems.  \n",
    "\n",
    "Other notes:\n",
    "We can train our own model, but there are ones out there that have been trained on all of wikipedia like GloVe which is what we will use here.  You can search for glove.6B.200d.txt to find the file.  It has all the weights and full dictionary of words. It has 200 dimensions for each word, and other larger vecotrs can be used if you want to train for more precision.\n",
    "\n",
    "It is best to set up pipelines so we can run multiple model types.  We can use traditional tree based, SVC, or logistic regression models.  \n",
    "\n",
    "A Sequential NN with LSTM or GRU will likely work better for more complex tasks but will require more training and tuning time.\n",
    "\n",
    "The input layer has to be a RNN type to deal with sequential data, then you can set up traditional NN (Dense, pooling, dropout etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-albania",
   "metadata": {},
   "source": [
    "### Project guidance\n",
    "The Flatiron curriculum had this as an optional project, and that's why I'm trying it to build some skills.\n",
    "\n",
    "Below is from the instructions:\n",
    "\n",
    "If you choose this option, you'll build an NLP model to analyze Twitter sentiment about Apple and Google products. The dataset comes from CrowdFlower via data.world. Human raters rated the sentiment in over 9,000 Tweets as positive, negative, or neither.\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "Build a model that can rate the sentiment of a Tweet based on its content.\n",
    "\n",
    "Aim for a Proof of Concept\n",
    "There are many approaches to NLP problems - start with something simple and iterate from there. For example, you could start by limiting your analysis to positive and negative Tweets only, allowing you to build a binary classifier. Then you could add in the neutral Tweets to build out a multiclass classifier. You may also consider using some of the more advanced NLP methods in the Mod 4 Appendix.\n",
    "\n",
    "\n",
    "#### Let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "copyrighted-element",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaronlee/opt/anaconda3/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from gensim.models import word2vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "optical-constant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9093\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Just took a survey on iPhone while in Starbuck...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7814</th>\n",
       "      <td>#blackberry users must feel like such losers h...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Anyone at #SXSW know if the apple store has ha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5742</th>\n",
       "      <td>RT @mention Free &amp;quot;Payments on the #Androi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>Listening to folks around the world making iPh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "221   Just took a survey on iPhone while in Starbuck...   \n",
       "7814  #blackberry users must feel like such losers h...   \n",
       "154   Anyone at #SXSW know if the apple store has ha...   \n",
       "5742  RT @mention Free &quot;Payments on the #Androi...   \n",
       "1220  Listening to folks around the world making iPh...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at                             emotion  \n",
       "221                              NaN  No emotion toward brand or product  \n",
       "7814                          iPhone                    Positive emotion  \n",
       "154                              NaN  No emotion toward brand or product  \n",
       "5742                             NaN  No emotion toward brand or product  \n",
       "1220                             NaN  No emotion toward brand or product  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('judge-1377884607_tweet_product_company.csv')\n",
    "df = df.sample(frac=1)  # CHANGE ME TO ADJUST SIZE OF DATASET USED\n",
    "df['emotion'] = df['is_there_an_emotion_directed_at_a_brand_or_product']\n",
    "df = df.drop(columns=['is_there_an_emotion_directed_at_a_brand_or_product'])\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-state",
   "metadata": {},
   "source": [
    "Now, let's transform the dataset\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "Store the column that will be the target, 'category', in the variable target\n",
    "Use the 'tweet_text' column's .map() method to use the word_tokenize function on every piece of text\n",
    "Store the .values attribute from the newly tokenized 'tweet_text' column in the variable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "approximate-tsunami",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9092 entries, 221 to 2732\n",
      "Data columns (total 3 columns):\n",
      " #   Column                           Non-Null Count  Dtype \n",
      "---  ------                           --------------  ----- \n",
      " 0   tweet_text                       9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at  3291 non-null   object\n",
      " 2   emotion                          9092 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 284.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['emotion', 'tweet_text'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acquired-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['emotion']\n",
    "data = df['tweet_text'].map(word_tokenize).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-communist",
   "metadata": {},
   "source": [
    "Loading A Pretrained GloVe Model\n",
    "\n",
    "\n",
    "For this project, I will be loading the pretrained weights from GloVe (short for Global Vectors for Word Representation ) from the Stanford NLP Group. \n",
    "\n",
    "These are commonly accepted as some of the best pre-trained word vectors available, and they're open source, so you can get them for free! Even the smallest file is still over 800 MB, so you'll you need to download this file manually.\n",
    "\n",
    "Note that there are several different sizes of pretrained word vectors available for download from the page linked above -- for the purposes of this lesson, you'll only need to use the smallest one, which still contains pretrained word vectors for over 6 billion words and phrases! To download this file, follow the link above and select the file called glove.6b.zip. For simplicity's sake, you can also start the download by clicking this link. You'll be using the GloVe file containing 50-dimensional word vectors for 6 billion words. Once you've downloaded the file, unzip it, and move the file glove.6B.50d.txt into the same directory as this Jupyter notebook.\n",
    "\n",
    "Since this is a 'proof of concept' project, I will just do the smaller glove to save time.\n",
    "\n",
    "Getting the Total Vocabulary\n",
    "Although the pretrained GloVe data contains vectors for 6 billion words and phrases, you don't need all of them. Instead, you only need the vectors for the words that appear in the dataset. If a word or phrase doesn't appear in the dataset, then there's no reason to waste memory storing the vector for that word or phrase.\n",
    "\n",
    "This means that you need to start by computing the total vocabulary of the dataset. You can do this by adding every word in the dataset into a Python set object. This is easy, since you've already tokenized each comment stored within data.\n",
    "\n",
    "In the cell below, add every token from every comment in data into a set, and store the set in the variable total_vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accomplished-state",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10665 unique words in the dataset.\n",
      "There are 9092 unique tweets in the dataset.\n"
     ]
    }
   ],
   "source": [
    "total_vocabulary = set(word.lower() for tweet in data for word in tweet)  # set created from nested comprehension \n",
    "print('There are {} unique words in the dataset.'.format(len(total_vocabulary)))\n",
    "print('There are {} unique tweets in the dataset.'.format(len(data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-settlement",
   "metadata": {},
   "source": [
    "### Extract Glove vectors\n",
    "We will take only the relevant words that exist in our dataset and see how that works.\n",
    "\n",
    "For testing, we will only use 20% of the dataset.  Later, if we have the resources, we will up that number.  Its in the first lines of code in this ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "numerical-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = {} # single dict to hold all of my words and vectors\n",
    "with open('glove.6B.200d.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        parts = line.split()  # go line by line and split to \n",
    "        word = parts[0].decode('utf-8')  # just pulls out the word, not the vectors\n",
    "        if word in total_vocabulary:\n",
    "            # if the word is in our dataset, we grab the vectors and put it in the glove dictionary\n",
    "            vector = np.array(parts[1:], dtype=np.float32)  # everything past the word is the vector\n",
    "            glove[word] = vector # add to dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-disco",
   "metadata": {},
   "source": [
    "After running the cell above, you now have all of the words and their corresponding vocabulary stored within the dictionary, glove, as key/value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hidden-theme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.046234 ,  0.1143   , -0.91583  , -0.35001  , -0.91413  ,\n",
       "        0.085852 , -0.39536  , -0.10104  , -0.031425 ,  0.33068  ,\n",
       "       -0.041772 ,  0.29488  , -0.3805   ,  0.6783   ,  0.61183  ,\n",
       "        0.26603  , -0.15935  ,  0.62045  , -0.90269  , -0.060473 ,\n",
       "       -0.3597   ,  2.7318   ,  0.2225   ,  0.38525  ,  0.03795  ,\n",
       "       -0.68665  ,  0.69095  ,  0.47121  , -0.076372 , -0.4115   ,\n",
       "        0.2448   , -0.61099  ,  0.14878  ,  0.62008  , -0.41831  ,\n",
       "        0.13992  , -0.13323  ,  0.048472 , -0.2632   ,  0.035318 ,\n",
       "        0.1374   , -0.5543   , -0.18643  ,  0.77533  ,  0.54598  ,\n",
       "        0.30443  , -0.027521 ,  0.50806  ,  0.62423  , -0.38892  ,\n",
       "        0.25972  ,  0.10713  , -0.14908  ,  0.10443  , -0.081065 ,\n",
       "        0.38875  ,  0.076677 , -0.45081  , -0.31744  , -0.18866  ,\n",
       "       -0.12292  ,  0.071915 , -0.10685  , -0.080957 ,  0.15643  ,\n",
       "        0.3556   , -0.2945   ,  0.088302 ,  0.74486  , -0.23338  ,\n",
       "       -0.091855 ,  0.44214  ,  0.3208   ,  0.47211  ,  0.28721  ,\n",
       "        1.1608   ,  0.55774  ,  0.53997  , -0.30509  , -0.67614  ,\n",
       "       -0.40713  ,  0.22411  , -0.82891  ,  0.097029 , -0.48357  ,\n",
       "       -0.15316  ,  0.067873 , -0.065764 , -0.062316 ,  0.26085  ,\n",
       "       -0.25682  ,  0.4891   ,  0.82646  , -0.28588  ,  0.16366  ,\n",
       "       -0.26442  , -0.67846  ,  0.23559  ,  0.27403  , -0.12921  ,\n",
       "       -0.062113 ,  0.025216 , -0.28685  ,  0.42522  ,  0.18832  ,\n",
       "        0.98399  , -0.56795  ,  1.2745   , -0.48817  ,  0.46992  ,\n",
       "        0.42874  , -0.082395 ,  0.30006  ,  0.22774  ,  0.43273  ,\n",
       "        0.017371 ,  0.092202 ,  0.25909  , -0.35875  , -0.51883  ,\n",
       "        0.20242  , -0.05803  ,  0.41946  , -0.24312  , -0.10708  ,\n",
       "       -0.80128  ,  0.19682  , -0.19543  ,  0.6547   ,  0.12323  ,\n",
       "       -0.32583  , -0.43842  ,  0.20505  , -0.54866  , -0.37439  ,\n",
       "        0.056119 ,  0.26851  ,  0.36363  , -0.25251  , -0.082359 ,\n",
       "       -0.20601  ,  0.21507  ,  0.14822  , -0.27392  ,  0.69821  ,\n",
       "       -0.1892   ,  0.64492  , -0.34958  ,  0.76385  ,  0.3366   ,\n",
       "       -0.078346 , -0.45069  ,  0.19429  , -0.056201 , -0.36269  ,\n",
       "        0.062878 ,  0.66848  ,  0.2602   , -0.2274   ,  0.19366  ,\n",
       "        0.22206  ,  0.34864  , -0.10071  ,  0.012262 , -0.24788  ,\n",
       "       -0.31372  , -0.36867  ,  0.11208  , -0.47637  , -0.27674  ,\n",
       "       -0.09348  ,  0.28223  ,  0.10644  , -0.41162  , -0.14354  ,\n",
       "        0.42186  , -0.0070552,  0.88066  , -0.20152  ,  0.078382 ,\n",
       "        1.1661   ,  0.42525  ,  0.07135  ,  0.10423  , -0.5856   ,\n",
       "       -0.3514   ,  0.36812  ,  0.93485  ,  0.48994  ,  0.49828  ,\n",
       "       -0.19452  , -1.196    , -0.28385  ,  0.24249  ,  0.58718  ,\n",
       "       -0.41428  ,  0.43804  ,  0.076073 ,  0.16939  ,  0.10746  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(glove))  # not as many words as above, but maybe some hashtags or misspellings etc not in set (check later)\n",
    "glove['worst'] # quick check.  I would assume worst will be in there when using reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-drain",
   "metadata": {},
   "source": [
    "### Create Mean Word Embeddings\n",
    "\n",
    "For this step, we will set up pipelines from scikit-learn. Using pipelines will save us time and make the code a bit cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "decent-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "class W2vVectorizer(object):\n",
    "    '''\n",
    "    word vector object that we can use in pipeline\n",
    "    '''\n",
    "    def __init__(self, w2v):\n",
    "        # Takes in a dictionary of words and vectors as input\n",
    "        self.w2v = w2v\n",
    "        if len(w2v) == 0:\n",
    "            self.dimensions = 0\n",
    "        else:\n",
    "            self.dimensions = len(w2v[next(iter(glove))])\n",
    "    \n",
    "    # Note: Even though it doesn't do anything, it's required that this object implement a fit method or else\n",
    "    # it can't be used in a scikit-learn pipeline  \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.w2v[w] for w in words if w in self.w2v]\n",
    "                   or [np.zeros(self.dimensions)], axis=0) for words in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-blame",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "Since we created a mean vectorizer class, you can pass this in as the first step in the pipeline, and then follow it up with the model you'll feed the data into for classification.\n",
    "\n",
    "Run the cell below to create pipeline objects that make use of the mean embedding vectorizer that was built above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "random-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf =  Pipeline([('Word2Vec Vectorizer', W2vVectorizer(glove)),\n",
    "              ('Random Forest', RandomForestClassifier(n_estimators=100, verbose=True))])\n",
    "svc = Pipeline([('Word2Vec Vectorizer', W2vVectorizer(glove)),\n",
    "                ('Support Vector Machine', SVC())])\n",
    "lr = Pipeline([('Word2Vec Vectorizer', W2vVectorizer(glove)),\n",
    "              ('Logistic Regression', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-running",
   "metadata": {},
   "source": [
    "Now, we create a list that contains a tuple for each pipeline, where the first item in the tuple is a name, and the second item in the list is the actual pipeline object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "measured-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('Random Forest', rf),\n",
    "          ('Support Vector Machine', svc),\n",
    "          ('Logistic Regression', lr)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-harvest",
   "metadata": {},
   "source": [
    "Use the list created above, and cross_val_score() function from scikit-learn to train all the models, and store their cross validation scores in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hazardous-school",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    5.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "/Users/aaronlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/aaronlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take a while to run depending on set size\n",
    "scores = [(name, cross_val_score(model, data, target, cv=2).mean()) for name, model, in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stock-duncan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Random Forest', 0.6221953365596129), ('Support Vector Machine', 0.615706115266168), ('Logistic Regression', 0.6254949406071271)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['No emotion toward brand or product', 'Positive emotion',\n",
       "       'Negative emotion', \"I can't tell\"], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(scores)\n",
    "df.emotion.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-lottery",
   "metadata": {},
   "source": [
    "These scores are pretty good.  There are 4 categories, so unweighted random would be 0.25.  We got around 0.60 with only 20% of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-hawaii",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "We used untuned supervised ML above.  Now let's try out the RNN method (the reason I wanted to do this project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "automated-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Sequential\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-component",
   "metadata": {},
   "source": [
    "One-hot encode the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "geological-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(target).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-munich",
   "metadata": {},
   "source": [
    "Now, you'll preprocess the tweet_text data. Use Keras' preprocessing tools to tokenize each example, convert them to sequences, and then pad the sequences so they're all the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "clean-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=20000)  # limit to the num_words most important ones\n",
    "tokenizer.fit_on_texts(list(df['tweet_text']))\n",
    "list_tokenized_headlines = tokenizer.texts_to_sequences(df['tweet_text'])\n",
    "X_t = sequence.pad_sequences(list_tokenized_headlines, maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-exclusive",
   "metadata": {},
   "source": [
    "## Split my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "internal-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_t, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-refund",
   "metadata": {},
   "source": [
    "Construct the neural network. In the embedding layer, specify the size you want the word vectors to be, as well as the size of the embedding space itself. The embedding size will be 128, and the size of the embedding space is best as the size of the total vocabulary that we're using.\n",
    "\n",
    "Once the data has passed through an embedding layer, you feed this data into an LSTM layer, followed by a Dense layer, followed by output layer. You also add some Dropout layers after each of these layers, to help fight overfitting.\n",
    "\n",
    "Our output layer is a Dense layer with 4 neurons, which corresponds to the 4 possible classes in the labels. You set the activation function for this output layer to 'softmax', so that the network will output a vector of predictions, where each element's value corresponds to the percentage chance that the example is the class that corresponds to that element, and where the sum of all elements in the output vector is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "original-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "floppy-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "model.add(Embedding(len(total_vocabulary), embedding_size))\n",
    "model.add(LSTM(25, return_sequences=True))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))  # use 4 because we have 4 categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-tunnel",
   "metadata": {},
   "source": [
    "Now compile model, and provide important parameters such as the loss function to use ('categorical_crossentropy', since this is a multiclass classification problem), and the optimizer to use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "conscious-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-endorsement",
   "metadata": {},
   "source": [
    "After compiling the model, you quickly check the summary of the model to see what the model looks like, and make sure the output shapes line up with what you expect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "metric-emperor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         1365120   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 25)          15400     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                1300      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 1,384,574\n",
      "Trainable params: 1,384,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-genetics",
   "metadata": {},
   "source": [
    "Finally, you can fit the model by passing in the data, the labels, and setting some other hyperparameters such as the batch size, the number of epochs to train for, and what percentage of the training data to use for validation data.\n",
    "\n",
    "Run the cell below and adjust the epochs as needed for time. T|raining will take some time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "better-workplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7273 7273\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "loose-attempt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "256/256 [==============================] - 24s 83ms/step - loss: 1.0823 - accuracy: 0.5339 - val_loss: 0.8919 - val_accuracy: 0.5989\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 0.9216 - accuracy: 0.5880 - val_loss: 0.8401 - val_accuracy: 0.6297\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.8005 - accuracy: 0.6520 - val_loss: 0.8173 - val_accuracy: 0.6692\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 17s 65ms/step - loss: 0.7030 - accuracy: 0.7305 - val_loss: 0.8603 - val_accuracy: 0.6670\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 17s 65ms/step - loss: 0.5818 - accuracy: 0.7751 - val_loss: 0.9293 - val_accuracy: 0.6538\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 17s 66ms/step - loss: 0.4976 - accuracy: 0.8029 - val_loss: 1.0766 - val_accuracy: 0.6703\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 16s 61ms/step - loss: 0.4380 - accuracy: 0.8357 - val_loss: 1.1627 - val_accuracy: 0.6637\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 18s 70ms/step - loss: 0.3722 - accuracy: 0.8619 - val_loss: 1.3075 - val_accuracy: 0.6659\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 17s 65ms/step - loss: 0.3507 - accuracy: 0.8744 - val_loss: 1.4971 - val_accuracy: 0.6714\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 16s 64ms/step - loss: 0.3186 - accuracy: 0.8830 - val_loss: 1.6772 - val_accuracy: 0.6725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd6cab4d910>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ⏰ This cell may take several minutes to run\n",
    "model.fit(X_t, y, epochs=10, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-corrections",
   "metadata": {},
   "source": [
    "# Evalute the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "nasty-burton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "piano-sunday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1819 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3\n",
       "0     0.0  0.0  1.0  0.0\n",
       "1     0.0  0.0  1.0  0.0\n",
       "2     0.0  0.0  1.0  0.0\n",
       "3     0.0  0.0  0.0  1.0\n",
       "4     0.0  0.0  1.0  0.0\n",
       "...   ...  ...  ...  ...\n",
       "1814  0.0  0.0  0.0  1.0\n",
       "1815  0.0  0.0  0.0  1.0\n",
       "1816  0.0  0.0  1.0  0.0\n",
       "1817  0.0  0.0  0.0  1.0\n",
       "1818  0.0  0.0  0.0  1.0\n",
       "\n",
       "[1819 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prediction(array, outcomes):\n",
    "    index = np.argmax(array)\n",
    "    array *= 0\n",
    "    array[index] = 1\n",
    "    return array\n",
    "    \n",
    "\n",
    "outcomes = df['emotion'].unique()\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = pd.DataFrame(y_pred).apply(lambda x: prediction(x, outcomes), axis=1)\n",
    "\n",
    "#outcomes\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "measured-franchise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1    2    3  \n",
      "0.0  0.0  1.0  0.0    1113\n",
      "          0.0  1.0     557\n",
      "     1.0  0.0  0.0     149\n",
      "dtype: int64\n",
      "No emotion toward brand or product    5388\n",
      "Positive emotion                      2978\n",
      "Negative emotion                       570\n",
      "I can't tell                           156\n",
      "Name: emotion, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.value_counts())  \n",
    "print(df['emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "simplified-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_ = pd.DataFrame(y_test).apply(lambda x: prediction(x, outcomes), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "timely-expansion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1819, 4) (1819, 4)\n",
      "(1819, 100) (1819, 4)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape, y_pred.shape)\n",
    "print(X_test.shape, y_test_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "excellent-growth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1819 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3\n",
       "0     0  0  1  0\n",
       "1     0  0  1  0\n",
       "2     0  0  1  0\n",
       "3     0  0  0  1\n",
       "4     0  0  1  0\n",
       "...  .. .. .. ..\n",
       "1814  0  0  0  1\n",
       "1815  0  0  0  1\n",
       "1816  0  0  1  0\n",
       "1817  0  0  0  1\n",
       "1818  0  0  0  1\n",
       "\n",
       "[1819 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "reasonable-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_ = y_test_.to_numpy()\n",
    "\n",
    "cm = confusion_matrix(y_test_.argmax(axis=1), y_pred.values.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "theoretical-retreat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5388\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "golden-opening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "outcomes = [ \"Can't tell\", 'Neg emotion', 'Pos emotion', 'No emotion']\n",
    "x_axis_labels = outcomes\n",
    "y_axis_labels = outcomes\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, cmap=\"Blues\",  xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.xlabel('Prediciton')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-alexandria",
   "metadata": {},
   "source": [
    "## How did we do?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "purple-beach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5388\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "quarterly-duration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Can't tell</th>\n",
       "      <th>Neg emotion</th>\n",
       "      <th>No emotion</th>\n",
       "      <th>Pos emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644295</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.910233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.935028</td>\n",
       "      <td>0.817742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fscore</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.747082</td>\n",
       "      <td>0.913103</td>\n",
       "      <td>0.861512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_occurrances</th>\n",
       "      <td>29.0</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>1062.000000</td>\n",
       "      <td>620.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Can't tell  Neg emotion   No emotion  Pos emotion\n",
       "precision             1.0     0.644295     0.892183     0.910233\n",
       "recall                0.0     0.888889     0.935028     0.817742\n",
       "fscore                0.0     0.747082     0.913103     0.861512\n",
       "n_occurrances        29.0   108.000000  1062.000000   620.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "results = precision_recall_fscore_support(y_test_, y_pred, zero_division=True)\n",
    "\n",
    "metrics = ['precision', 'recall', 'fscore', 'n_occurrances']\n",
    "outcomes = [ \"Can't tell\", 'Neg emotion', 'No emotion', 'Pos emotion']\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=outcomes, index=metrics)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you just want to print them or do some manipulation, use this code below\n",
    "\n",
    "# for metric, result in zip(metrics, results):\n",
    "#     for i, label in enumerate(outcomes):\n",
    "#         print('{} {}: {:.2f}'.format(label, metric, result[i]))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eastern-shelter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall precision of RNN: 0.877\n"
     ]
    }
   ],
   "source": [
    "# what was the overall precision\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "print('Overall precision of RNN: {:.3f}'.format(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-collection",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "The confusion matrix shows that there were very few tweets graded as negative or can't.  The neural network doesn't predict any negatives due to the small number.\n",
    "\n",
    "More than half are positive emotions, and rest is split between 'can't tell' and 'no emotion'.  \n",
    "\n",
    "The model predicts at nearly 90% accuracy against the test set.  The base supervised modesl (untuned) only scored around 60% by comparison.  The RNN is well suited for this task.  \n",
    "\n",
    "A larger dataset, or perhaps a more negative dataset might help train the model to make predictions at a higher rate.  In the current state, it would be unabl to pick out the negative sentiment.  Barring a larger dataset, we could oversample the minority class randomly or using SMOTE.  This would make the model more sensitive to 'negative' sentiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-merit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
